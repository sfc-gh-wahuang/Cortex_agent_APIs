USE ROLE HOL2;
USE DATABASE HOL2_DB;
USE SCHEMA HOL2_SCHEMA;
USE WAREHOUSE HOL2_WH;

-- Cortex Analyst runner for a single question
CREATE OR REPLACE PROCEDURE CORTEX_ANALYST_SQL(prompt STRING, database STRING, SCHEMA STRING, SEMANTIC_VIEW_NAME STRING)
RETURNS STRING
LANGUAGE PYTHON
PACKAGES = ('snowflake-snowpark-python')
RUNTIME_VERSION = '3.11'
HANDLER = 'process_message'
as
$$
import _snowflake
import json
def send_message(messages, database, schema, semantic_view_name):
    """Calls the REST API and returns the response."""

    request_body = {
        "messages": messages,
        "semantic_view": f"{database}.{schema}.{semantic_view_name}",
    }
    resp = _snowflake.send_snow_api_request(
            "POST",
            f"/api/v2/cortex/analyst/message",
            {},
            {},
            request_body,
            {},
            30000,
        )
    if resp["status"] < 400:
        response_content = json.loads(resp["content"])
        return response_content
    else:
        raise Exception(
            f"Failed request with status {resp['status']}: {resp}"
        )

def process_message(session, prompt, database, schema, semantic_view_name):
    """Processes a message and adds the response to the chat."""
    messages = []
    messages.append(
        {"role": "user", "content": [{"type": "text", "text": prompt}]}
    )
    response = send_message(messages, database, schema, semantic_view_name)
    for item in response["message"]["content"]:
        if item["type"] == "sql":
            return item.get("statement", None).replace(";", "").replace("-- Generated by Cortex Analyst", "")
    else:
        return None
$$;

-- LS @SEMANTIC_MODEL;

SHOW SEMANTIC VIEWS;

CALL CORTEX_ANALYST_SQL(
    'For each month, what was the lowest daily revenue and on what date did that lowest revenue occur?',
    'HOL2_DB',
    'HOL2_SCHEMA',
    'REVENUE'
);

-- loop through a table (of which 1 column is the question) and call the stored procedure for each row
-- to generate "GENERATED_SQL" and save to output_table
CREATE OR REPLACE PROCEDURE GENERATE_SQL_ALL(
    INPUT_TABLE STRING,
    DB_NAME STRING,
    SCHEMA_NAME STRING,
    VIEW_NAME STRING,
    OUTPUT_TABLE STRING
)
RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-snowpark-python')
HANDLER = 'generate_sql_all'
AS
$$
from snowflake.snowpark import Session

def generate_sql_all(session: Session, INPUT_TABLE: str, DB_NAME: str, SCHEMA_NAME: str, VIEW_NAME: str, OUTPUT_TABLE: str) -> str:
    # Load the input data
    df = session.sql(f"SELECT question, expected_sql FROM {INPUT_TABLE}")

    result_rows = []

    for row in df.collect():
        question = row['QUESTION']
        expected_sql = row['EXPECTED_SQL']

        try:
            # Call stored procedure
            result = session.sql(
                "CALL CORTEX_ANALYST_SQL(?, ?, ?, ?)",
                params=[question, DB_NAME, SCHEMA_NAME, VIEW_NAME]
            ).collect()

            generated_sql = result[0][0]

        except Exception as e:
            # Capture error message instead of failing
            generated_sql = f"[ERROR]: {str(e)}"

        # Append result row
        result_rows.append((question, expected_sql, generated_sql))

    # Create a dataframe with results
    result_df = session.create_dataframe(result_rows, schema=["question", "expected_sql", "generated_sql"])

    # Append to the output table
    result_df.write.mode("append").save_as_table(OUTPUT_TABLE)

    return f"Inserted {len(result_rows)} rows into {OUTPUT_TABLE}"
$$;

select * from SQL_QUESTIONS; -- QUESTION | EXPECTED_SQL


-- SQL_QUESTIONS is a table with columns QUESTION and EXPECTED_SQL
-- @HOL2_DB.HOL2_SCHEMA.REVENUE is the semantic view
CALL GENERATE_SQL_ALL(
    'HOL2_DB.HOL2_SCHEMA.SQL_QUESTIONS',
    'HOL2_DB',
    'HOL2_SCHEMA',
    'REVENUE',
    'HOL2_DB.HOL2_SCHEMA.EVAL_RESULTS'
);


-- sproc to call LLM to evaluate accuracy of the generated SQLs
CREATE OR REPLACE PROCEDURE evaluate_all_samples(
    tbl_name STRING,
    model_name STRING
)
RETURNS STRING
LANGUAGE PYTHON
RUNTIME_VERSION = '3.11'
PACKAGES = ('snowflake-snowpark-python')
HANDLER = 'main'
AS
$$
from snowflake.snowpark import Session
from snowflake.snowpark import functions as F

SQLAccuracy_prompt = """You are evaluating JSON data against ground truth JSON data.
The JSON data is the output of a SQL query generated to answer a user question.
You are to determine if the provided JSON data matches the ground truth JSON data
and answers the user question.
The Inference JSON does not have to match the Ground Truth JSON perfectly but should contain the correct answer as denoted by the Ground Truth JSON.
Your answer should be either "True" or "False".
Answer "True" if you believe the Inference JSON data reflects the Ground Truth JSON data given the user question.
Otherwise, answer "False".
[User Question]
{question}

[The Start of the Inference JSON Data]
{inference_data}
[The End of the Inference JSON Data]

[The Start of the Ground Truth Data]
{expected_data}
[The End of the Ground Truth Data]
"""

def return_sql_result(session: Session, sql: str) -> str:
    try:
        result = (
            session.sql(sql.replace(";", ""))
            .limit(100)
            .select(F.to_varchar(F.array_agg(F.object_construct("*"))))
        )
        return result.collect_nowait().result()[0][0]
    except Exception as e:
       return f"Error: {e}"

def run_async_sql_complete(session: Session, model: str, prompt: str) -> str:
    prompt = prompt.replace("'", "\\'")
    query = f"""SELECT
    TRIM(snowflake.cortex.complete('{model}',
    '{prompt}'))"""
    return session.sql(query).collect_nowait().result()[0][0]

def main(session: Session, tbl_name: str, model_name: str) -> str:
    if model_name is None:
        model_name = "llama3.1-70b"

    # Load data from table
    df = session.table(tbl_name)
    rows = df.collect()
    
    total = len(rows)
    true_count = 0

    return_msg = ""

    for i, row in enumerate(rows, 1):
        question = row['QUESTION']
        generated_sql = row['GENERATED_SQL']
        expected_sql = row['EXPECTED_SQL']

        inference_data = return_sql_result(session, generated_sql)
        expected_data = return_sql_result(session, expected_sql)

        # If there's an error in retrieving results, skip
        if inference_data.startswith("Error") or expected_data.startswith("Error"):
            return_msg += (f"[{i}/{total}] Skipped due to SQL error \n")
            continue

        fstrings = {
            "question": question,
            "inference_data": inference_data,
            "expected_data": expected_data,
        }
        prompt = SQLAccuracy_prompt.format(**fstrings)

        try:
            result = run_async_sql_complete(session, model_name, prompt)
            if result.strip().lower() == "true":
                true_count += 1
            return_msg += (f"[{i}/{total}] Result: {result}\n")
        except Exception as e:
            return_msg += (f"[{i}/{total}] Cortex Error: {e}\n")

    accuracy = (true_count / total) * 100 if total > 0 else 0
    return_msg += (f"Evaluation complete: {true_count}/{total} correct ({accuracy:.2f}%)")
    return return_msg
$$;

CALL evaluate_all_samples('EVAL_RESULTS', 'llama3.1-70b');
